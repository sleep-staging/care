{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Lukas Gemein <l.gemein@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "from braindecode.datasets import TUH\n",
    "from braindecode.preprocessing import (\n",
    "    preprocess, Preprocessor, create_fixed_length_windows, scale as multiply)\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "mne.set_log_level('ERROR')  # avoid messages everytime a window is extracted\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets.tuh import _TUHMock as TUH  # noqa F811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUH_PATH = '/scratch/tuh/'\n",
    "N_JOBS = 2  # specify the number of jobs for loading and windowing\n",
    "tuh = TUH(\n",
    "    path=TUH_PATH,\n",
    "    recording_ids=None,\n",
    "    target_name=None,\n",
    "    preload=False,\n",
    "    add_physician_reports=False,\n",
    "    n_jobs=1 if TUH.__name__ == '_TUHMock' else N_JOBS,  # Mock dataset can't\n",
    "    # be loaded in parallel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "genders = tuh.description.gender.unique()\n",
    "x = [tuh.description.age[tuh.description.gender == g] for g in genders]\n",
    "ax.hist(\n",
    "    x=x,\n",
    "    stacked=True,\n",
    "    bins=np.arange(100, dtype=int),\n",
    "    alpha=.5,\n",
    ")\n",
    "ax.legend(genders)\n",
    "ax.set_xlabel('Age [years]')\n",
    "ax.set_ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_example_data(preload, window_len_s, n_subjects=10):\n",
    "    \"\"\"Create windowed dataset from subjects of the TUH Abnormal dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    preload: bool\n",
    "        If True, use eager loading, otherwise use lazy loading.\n",
    "    n_subjects: int\n",
    "        Number of subjects to load.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    windows_ds: BaseConcatDataset\n",
    "        Windowed data.\n",
    "\n",
    "    .. warning::\n",
    "        The recordings from the TUH Abnormal corpus do not all share the same\n",
    "        sampling rate. The following assumes that the files have already been\n",
    "        resampled to a common sampling rate.\n",
    "    \"\"\"\n",
    "    subject_ids = list(range(n_subjects))\n",
    "    ds = TUHAbnormal(\n",
    "        TUH_PATH, subject_ids=subject_ids, target_name='pathological',\n",
    "        preload=preload)\n",
    "\n",
    "    fs = ds.datasets[0].raw.info['sfreq']\n",
    "    window_len_samples = int(fs * window_len_s)\n",
    "    window_stride_samples = int(fs * 4)\n",
    "    # window_stride_samples = int(fs * window_len_s)\n",
    "    windows_ds = create_fixed_length_windows(\n",
    "        ds, start_offset_samples=0, stop_offset_samples=None,\n",
    "        window_size_samples=window_len_samples,\n",
    "        window_stride_samples=window_stride_samples, drop_last_window=True,\n",
    "        preload=preload, drop_bad_windows=True)\n",
    "\n",
    "    # Drop bad epochs\n",
    "    # XXX: This could be parallelized.\n",
    "    # XXX: Also, this could be implemented in the Dataset object itself.\n",
    "    for ds in windows_ds.datasets:\n",
    "        ds.windows.drop_bad()\n",
    "        assert ds.windows.preload == preload\n",
    "\n",
    "    return windows_ds\n",
    "\n",
    "\n",
    "def create_example_model(n_channels, n_classes, window_len_samples,\n",
    "                         kind='shallow', cuda=False):\n",
    "    \"\"\"Create model, loss and optimizer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_channels : int\n",
    "        Number of channels in the input\n",
    "    n_times : int\n",
    "        Window length in the input\n",
    "    n_classes : int\n",
    "        Number of classes in the output\n",
    "    kind : str\n",
    "        'shallow' or 'deep'\n",
    "    cuda : bool\n",
    "        If True, move the model to a CUDA device.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : torch.nn.Module\n",
    "        Model to train.\n",
    "    loss :\n",
    "        Loss function\n",
    "    optimizer :\n",
    "        Optimizer\n",
    "    \"\"\"\n",
    "    if kind == 'shallow':\n",
    "        model = ShallowFBCSPNet(\n",
    "            n_channels, n_classes, input_window_samples=window_len_samples,\n",
    "            n_filters_time=40, filter_time_length=25, n_filters_spat=40,\n",
    "            pool_time_length=75, pool_time_stride=15, final_conv_length='auto',\n",
    "            split_first_layer=True, batch_norm=True, batch_norm_alpha=0.1,\n",
    "            drop_prob=0.5)\n",
    "    elif kind == 'deep':\n",
    "        model = Deep4Net(\n",
    "            n_channels, n_classes, input_window_samples=window_len_samples,\n",
    "            final_conv_length='auto', n_filters_time=25, n_filters_spat=25,\n",
    "            filter_time_length=10, pool_time_length=3, pool_time_stride=3,\n",
    "            n_filters_2=50, filter_length_2=10, n_filters_3=100,\n",
    "            filter_length_3=10, n_filters_4=200, filter_length_4=10,\n",
    "            first_pool_mode=\"max\", later_pool_mode=\"max\", drop_prob=0.5,\n",
    "            double_time_convs=False, split_first_layer=True, batch_norm=True,\n",
    "            batch_norm_alpha=0.1, stride_before_pool=False)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    loss = nn.NLLLoss()\n",
    "\n",
    "    return model, loss, optimizer\n",
    "\n",
    "\n",
    "def run_training(model, dataloader, loss, optimizer, n_epochs=1, cuda=False):\n",
    "    \"\"\"Run training loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        Model to train.\n",
    "    dataloader : torch.utils.data.Dataloader\n",
    "        Data loader which will serve examples to the model during training.\n",
    "    loss :\n",
    "        Loss function.\n",
    "    optimizer :\n",
    "        Optimizer.\n",
    "    n_epochs : int\n",
    "        Number of epochs to train the model for.\n",
    "    cuda : bool\n",
    "        If True, move X and y to CUDA device.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : torch.nn.Module\n",
    "        Trained model.\n",
    "    \"\"\"\n",
    "    for i in range(n_epochs):\n",
    "        loss_vals = list()\n",
    "        for X, y, _ in dataloader:\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "\n",
    "            y = y.long()\n",
    "            if cuda:\n",
    "                X, y = X.cuda(), y.cuda()\n",
    "\n",
    "            loss_val = loss(model(X), y)\n",
    "            loss_vals.append(loss_val.item())\n",
    "\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {i + 1} - mean training loss: {np.mean(loss_vals)}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from braindecode.datasets import TUHAbnormal\n",
    "from braindecode.preprocessing import create_fixed_length_windows\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRELOAD = [True, False]  # True -> eager loading; False -> lazy loading\n",
    "N_SUBJECTS = [10]  # Number of recordings to load from the TUH Abnormal corpus\n",
    "WINDOW_LEN_S = [2, 4, 15]  # Window length, in seconds\n",
    "N_EPOCHS = [2]  # Number of epochs to train the model for\n",
    "BATCH_SIZE = [64, 256]  # Training minibatch size\n",
    "MODEL = ['shallow', 'deep']\n",
    "\n",
    "NUM_WORKERS = [8, 0]  # number of processes used by pytorch's Dataloader\n",
    "PIN_MEMORY = [False]  # whether to use pinned memory\n",
    "CUDA = [True, False] if torch.cuda.is_available() else [False]  # whether to use a CUDA device\n",
    "\n",
    "N_REPETITIONS = 3  # Number of times to repeat the experiment (to get better time estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUH_PATH = ('/scratch/tuh/edf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Repetition 1/3:\n",
      "{'repetition': 0, 'preload': True, 'n_subjects': 10, 'win_len_s': 2, 'n_epochs': 2, 'batch_size': 64, 'model_kind': 'shallow', 'num_workers': 8, 'pin_memory': False, 'cuda': True}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'subject_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m     22\u001b[0m data_loading_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 23\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_example_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_len_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_subjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_subjects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m data_loading_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Create the data loader\u001b[39;00m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mload_example_data\u001b[0;34m(preload, window_len_s, n_subjects)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Create windowed dataset from subjects of the TUH Abnormal dataset.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    resampled to a common sampling rate.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m subject_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(n_subjects))\n\u001b[0;32m---> 22\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mTUHAbnormal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTUH_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubject_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpathological\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m fs \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mdatasets[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msfreq\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m window_len_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(fs \u001b[38;5;241m*\u001b[39m window_len_s)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'subject_ids'"
     ]
    }
   ],
   "source": [
    "all_results = list()\n",
    "for (i, preload, n_subjects, win_len_s, n_epochs, batch_size, model_kind,\n",
    "        num_workers, pin_memory, cuda) in product(\n",
    "            range(N_REPETITIONS), PRELOAD, N_SUBJECTS, WINDOW_LEN_S, N_EPOCHS,\n",
    "            BATCH_SIZE, MODEL, NUM_WORKERS, PIN_MEMORY, CUDA):\n",
    "\n",
    "    results = {\n",
    "        'repetition': i,\n",
    "        'preload': preload,\n",
    "        'n_subjects': n_subjects,\n",
    "        'win_len_s': win_len_s,\n",
    "        'n_epochs': n_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'model_kind': model_kind,\n",
    "        'num_workers': num_workers,\n",
    "        'pin_memory': pin_memory,\n",
    "        'cuda': cuda\n",
    "    }\n",
    "    print(f'\\nRepetition {i + 1}/{N_REPETITIONS}:\\n{results}')\n",
    "\n",
    "    # Load the dataset\n",
    "    data_loading_start = time.time()\n",
    "    dataset = load_example_data(preload, win_len_s, n_subjects=n_subjects)\n",
    "    data_loading_end = time.time()\n",
    "\n",
    "    # Create the data loader\n",
    "    training_setup_start = time.time()\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False, pin_memory=pin_memory,\n",
    "        num_workers=num_workers, worker_init_fn=None)\n",
    "\n",
    "    # Instantiate model and optimizer\n",
    "    n_channels = len(dataset.datasets[0].windows.ch_names)\n",
    "    n_times = len(dataset.datasets[0].windows.times)\n",
    "    n_classes = 2\n",
    "    model, loss, optimizer = create_example_model(\n",
    "        n_channels, n_classes, n_times, kind=model_kind, cuda=cuda)\n",
    "    training_setup_end = time.time()\n",
    "\n",
    "    # Start training loop\n",
    "    model_training_start = time.time()\n",
    "    trained_model = run_training(\n",
    "        model, dataloader, loss, optimizer, n_epochs=n_epochs, cuda=cuda)\n",
    "    model_training_end = time.time()\n",
    "\n",
    "    del dataset, model, loss, optimizer, trained_model\n",
    "\n",
    "    # Record timing results\n",
    "    results['data_preparation'] = data_loading_end - data_loading_start\n",
    "    results['training_setup'] = training_setup_end - training_setup_start\n",
    "    results['model_training'] = model_training_end - model_training_start\n",
    "    all_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
